{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1BRPGVwfbt"
      },
      "source": [
        "\n",
        "\n",
        "## <img src='https://raw.githubusercontent.com/UndeadSec/SocialFishMobile/master/content/logo.png' height=\"30\" alt=\"SocialFish\" /> SocialFish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tVcSpw5wx_jX"
      },
      "outputs": [],
      "source": [
        "#@markdown <h3>⬅️ Click Here to START</h3>\n",
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/UndeadSec/SocialFishMobile/master/content/logo.png' height=\"100\" alt=\"SocialFish\"/></center>\n",
        "#@markdown <center><h3>SocialGPT<br />Content Automation Tool & Desigend To Convert Audio into Video</h3></center><br>\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def play(f):\n",
        "    mp4 = open(f, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)\n",
        "\n",
        "# Install required packages\n",
        "subprocess.run(['apt', 'install', 'imagemagick'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['cat', '/etc/ImageMagick-6/policy.xml', '|', 'sed', 's/none/read,write/g', '>', '/etc/ImageMagick-6/policy.xml'])\n",
        "subprocess.run(['wget', '-qO-', 'http://keyserver.ubuntu.com/pks/lookup?op=get&search=0x6888550b2fc77d09', '|', 'sudo', 'tee', '/etc/apt/trusted.gpg.d/songrec.asc'])\n",
        "subprocess.run(['sudo', 'apt-add-repository', 'ppa:marin-m/songrec', '-y', '-u'])\n",
        "subprocess.run(['sudo', 'apt', 'install', 'songrec', '-y'])\n",
        "subprocess.run(['pip', 'install', 'youtube-transcript-api', 'langchain', 'langchain_openai', 'openai', 'requests', 'moviepy==2.0.0.dev2', 'imageio==2.25.1', 'pysrt==1.1.2', 'Pillow==9.5.0', 'ffmpeg-python', 'pytube', 'google-api-python-client', 'google-auth-oauthlib', 'google-auth-httplib2', 'oauth2client', 'git+https://github.com/m1guelpf/auto-subtitle.git'])\n",
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/NIKHTU01/SocialGPT\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "urdu_stopwords = pd.read_csv(\"/content/SocialGPT/Stopwords.csv\")\n",
        "Urdu_alphabets = pd.read_csv(\"/content/SocialGPT/Alphabets.csv\")\n",
        "urdu_stopwords.head()\n",
        "def urdu_to_roman(Urdu_string):\n",
        "    Urdu_string_lst=Urdu_string.split()\n",
        "    roman_lst=[]\n",
        "    for word in Urdu_string_lst:\n",
        "        temp = word\n",
        "        for idx, stopword in enumerate(urdu_stopwords['urdu']):\n",
        "            if stopword==word:\n",
        "                temp = urdu_stopwords.iloc[idx]['roman']\n",
        "                break\n",
        "        for i, j in enumerate(Urdu_alphabets['urdu']):\n",
        "            temp = temp.replace(j , Urdu_alphabets.iloc[i]['roman'])\n",
        "        roman_lst.append(temp)\n",
        "    Roman_string=' '.join(roman_lst)\n",
        "    return Roman_string\n",
        "\n",
        "Urdu_string = 'میرا نام عبداللہ ہے'\n",
        "Roman_string = urdu_to_roman(Urdu_string)\n",
        "#####################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xvIxkIPvOsn8"
      },
      "outputs": [],
      "source": [
        "\n",
        "OPENAI_API_KEY = \"sk-K56wyCwEx0uPp9gC1A0eZRI7uC8lmfk4l2Aj\"  #@param {type:\"string\"}\n",
        "PEXELS_API_KEY = \"7KygQ5s3taAlOZSuwdwsJQ12SeSaGJo6GeVaP70shik\" #@param {type:\"string\"}\n",
        "#CLIENT_SECRETS = \"\" #@param {type:\"string\"}\n",
        "INPUT_MEDIA = \"/content/drive/MyDrive/profection.wav\"  #@param {type:\"string\"}\n",
        "#BG_MUSIC = \"\"  # @param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"PEXELS_API_KEY\"] = PEXELS_API_KEY\n",
        "os.environ[\"CLIENT_SECRETS\"] = CLIENT_SECRETS\n",
        "#####################################\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "directory_path = \"output\"\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Directory '{directory_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Directory '{directory_path}' already exists.\")\n",
        "\n",
        "# Clean all logs\n",
        "shutil.rmtree('/content/logs', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_lkWTNvaJW",
        "outputId": "d8df689b-10f7-4622-b298-13003a39396f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice Generated: voice.mp3 | Duration: 60s\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import AudioFileClip\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the path where the voice will be saved\n",
        "voice_path = \"output/voice.mp3\"\n",
        "\n",
        "# Check if the input media path is provided\n",
        "if INPUT_MEDIA.strip() == \"\":\n",
        "    # Generate TTS voice based on the predefined script\n",
        "    client = OpenAI()\n",
        "    response = client.audio.speech.create(\n",
        "        model=\"tts-1-hd\",\n",
        "        voice=\"onyx\",\n",
        "        input=script,\n",
        "    )\n",
        "\n",
        "    # Write the generated TTS voice to the voice_path\n",
        "    with open(voice_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    # Copy the provided input media to the output directory and rename it as voice.mp3\n",
        "    output_dir = \"/content/output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the provided input media to the output directory and rename it as voice.mp3\n",
        "    shutil.copy(INPUT_MEDIA, voice_path)\n",
        "\n",
        "#####################################\n",
        "\n",
        "# Get the duration of input media\n",
        "audio = AudioFileClip(voice_path)\n",
        "duration_in_seconds = round(audio.duration)\n",
        "\n",
        "# Print the name of the voiceover file and its duration\n",
        "print(f\"Voice Generated: {voice_path.split('/')[-1]} | Duration: {duration_in_seconds}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps-Sg10bxgkp",
        "outputId": "1e91f61b-9375-4c19-c67f-390ee181be1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting audio from voice...\n",
            "Generating subtitles for voice... This might take a while.\n",
            "100% 5960/5960 [03:03<00:00, 32.40frames/s]\n"
          ]
        }
      ],
      "source": [
        "#####################################\n",
        "# Generating Captions please change the input media file language\n",
        "\n",
        "!auto_subtitle \"output/voice.mp3\" --srt_only \"True\" --output_dir \"output\" --language \"ur\"\n",
        "import pysrt\n",
        "import string\n",
        "\n",
        "subs = pysrt.open('output/voice.srt')\n",
        "for sub in subs:\n",
        "    sub.text = sub.text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    if len(sub.text) > 20:\n",
        "        words = sub.text.split()\n",
        "        lines = []\n",
        "        current_line = \"\"\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) <= 30:\n",
        "                current_line += word.title() + \" \"\n",
        "            else:\n",
        "                lines.append(current_line.strip())\n",
        "                current_line = word.title() + \" \"\n",
        "        if current_line:\n",
        "            lines.append(current_line.strip())\n",
        "        sub.text = \"\\n\".join(lines)\n",
        "    else:\n",
        "        sub.text = sub.text.title()\n",
        "subs.save(\"output/voice.srt\")\n",
        "#might take some time (approx 3- 5min depending on audio length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "FoTlYYwp3SnK",
        "outputId": "a9065b4b-174e-4daf-ecfc-ff6cec0d074d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d66b126994fd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m template = \"\"\"Imagine you're a highly imaginative artist with the unique ability to map the subjects\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from langchain_openai.chat_models import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m from langchain_openai.embeddings import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m __all__ = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"ChatOpenAI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/azure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSecretStr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_validator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxiesTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionDefinition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFunctionDefinition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionParameters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFunctionParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from ._types import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mBody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mIncEx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhttpx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAsyncBaseTransport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"Imagine you're a highly imaginative artist with the unique ability to map the subjects\n",
        "in a given SRT caption to a one word real-world objects and scenes.\n",
        "It's important to keep the titles exactly one word, and title must be a real word object or scences\n",
        "That human can vision, avoid providing teoritocal titles like: Paradox, Chrysalis, Journey, Reality, Accomplishment\n",
        "Instead use real world titles that can bee seen by human eyes like Mansion, Yoga, Car, Money.\n",
        "Give me exactly {num_clips} distinct clip titles.\n",
        "Each title should seamlessly flow into the next, creating a captivating narrative,\n",
        "and each title will be precisely 5 seconds long.\n",
        "I want you to understand and imagine the big picture of the video and give me titles that matches\n",
        "The entire video, not just invidual scences.\n",
        "\n",
        "Get inspired by the SRT caption provided:\n",
        "\n",
        "{srt_caption}\n",
        "\n",
        "Output Instruction:\n",
        "Provide only the titles. Each title must be separated by a new line,\n",
        "do not mention numbers in titles and titles must be URL-encoded friendly.\n",
        "Example Output:\n",
        "Yoga\n",
        "Forest\n",
        "Office\n",
        "Jogging\n",
        "Sunset\n",
        "Cafe\n",
        "Hiking\n",
        "Spa\n",
        "Beach\n",
        "Tea\n",
        "Luxury\n",
        "Money\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "num_clips = (duration_in_seconds // 5) + 1\n",
        "\n",
        "with open(\"output/voice.srt\", \"r\") as f:\n",
        "  srt_caption = f.read()\n",
        "  output = chain.invoke({\"num_clips\": num_clips, \"srt_caption\": srt_caption})\n",
        "\n",
        "clips_titles = output.strip().split(\"\\n\")\n",
        "clips_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o17lfo7PrV0"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "# Preparing Assets\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "from collections import Counter\n",
        "from moviepy.editor import AudioFileClip\n",
        "\n",
        "\n",
        "clip_counter = Counter(clips_titles)\n",
        "clips_paths = []\n",
        "selected_videos = set()\n",
        "\n",
        "for title, count in clip_counter.items():\n",
        "    headers = {\n",
        "        \"Authorization\": os.environ[\"PEXELS_API_KEY\"],\n",
        "    }\n",
        "    url = f\"https://api.pexels.com/videos/search?query={title}&per_page=15&orientation=portrait&size=medium\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        videos = response.json()[\"videos\"]\n",
        "        for i in range(count):\n",
        "            available_videos = [\n",
        "                video\n",
        "                for video in videos\n",
        "                if video[\"video_files\"][0][\"link\"] not in selected_videos\n",
        "            ]\n",
        "            if not available_videos:\n",
        "                print(f\"No more available videos for title '{title}'.\")\n",
        "                break\n",
        "\n",
        "            video = random.choice(available_videos)\n",
        "            video_url = video[\"video_files\"][0][\"link\"]\n",
        "            temp_name = f\"{title}_{i}.mp4\"\n",
        "            video_path = os.path.join(\"output\", temp_name)\n",
        "            with open(video_path, \"wb\") as video_file:\n",
        "                video_file.write(requests.get(video_url).content)\n",
        "            clips_paths.append(video_path)\n",
        "            selected_videos.add(video_url)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Failed to fetch videos for title '{title}'. Status code: {response.status_code}\"\n",
        "        )\n",
        "\n",
        "for i in range(num_clips - len(clips_paths)):\n",
        "  clips_paths.append(clips_paths[0])\n",
        "\n",
        "clips_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlqM7fJ-2NIE"
      },
      "outputs": [],
      "source": [
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from moviepy.video.fx.all import resize\n",
        "\n",
        "\n",
        "def resize_clip(input_video_path, duration=5, new_dimensions = (720, 1280)):\n",
        "    video_clip = VideoFileClip(input_video_path)\n",
        "    total_duration = video_clip.duration\n",
        "    start_time = (total_duration - duration) / 2\n",
        "    end_time = start_time + duration\n",
        "    video_clip = video_clip.subclip(start_time, end_time)\n",
        "\n",
        "    video_clip = resize(video_clip, new_dimensions)\n",
        "    return video_clip\n",
        "\n",
        "\n",
        "clips = [resize_clip(cp) for cp in clips_paths]\n",
        "clips\n",
        "#####################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5kF_C-74sdv",
        "outputId": "829435fd-a60b-4b27-ec1c-811efa50190b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output/composite_video.mp4.\n",
            "MoviePy - Writing audio in composite_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output/composite_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output/composite_video.mp4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from moviepy.editor import VideoFileClip, CompositeAudioClip, concatenate_videoclips, AudioFileClip\n",
        "from moviepy.audio.fx.all import volumex\n",
        "\n",
        "# Ensure the 'output' directory exists\n",
        "if not os.path.exists('output'):\n",
        "    os.makedirs('output')\n",
        "\n",
        "# Initialize an empty music_audio variable\n",
        "music_audio = None\n",
        "\n",
        "# Check if BG_MUSIC is provided\n",
        "if BG_MUSIC.strip():\n",
        "    # Download the background music\n",
        "    music_response = requests.get(BG_MUSIC)\n",
        "\n",
        "    # Save the music file to 'output/music.mp3'\n",
        "    with open('output/music.mp3', 'wb') as music_file:\n",
        "        music_file.write(music_response.content)\n",
        "\n",
        "    # Load and process the background music\n",
        "    music_audio = AudioFileClip(\"output/music.mp3\").fx(volumex, 0.3)  # Adjusted volume level to 0.3\n",
        "    t_start = int(music_audio.duration // 2 - duration_in_seconds // 2)\n",
        "    music_audio = music_audio.subclip(t_start, duration_in_seconds + t_start)\n",
        "\n",
        "# Load and process the voice audio\n",
        "voice_audio = AudioFileClip(\"output/voice.mp3\").fx(volumex, 3)\n",
        "\n",
        "# Combine the voice audio with background music if it exists\n",
        "if music_audio:\n",
        "    audio = CompositeAudioClip([voice_audio, music_audio])\n",
        "else:\n",
        "    audio = voice_audio\n",
        "\n",
        "\n",
        "# Uncomment the following line and ensure it correctly concatenates the video clips\n",
        "final_clip = concatenate_videoclips(clips, method=\"compose\").subclip(0, duration_in_seconds)\n",
        "\n",
        "# Set the audio for the final clip\n",
        "final_clip = final_clip.set_audio(audio)\n",
        "\n",
        "# Write the final video file\n",
        "final_clip.write_videofile(\"output/composite_video.mp4\", codec=\"libx264\", audio_codec=\"aac\", fps=24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LkTCGDI7GER"
      },
      "outputs": [],
      "source": [
        "play(\"output/composite_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2RdkTPBhjaa",
        "outputId": "93fca272-0ed9-461f-9319-0f7872a92c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output/final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output/final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output/final_video.mp4\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Subtitle Settings\n",
        "use_subtitles = \"YES\" #@param [\"YES\", \"NO\"]\n",
        "subtitle_font = \"Noto Nastaliq Urdu\" #@param [\"impact\", \"/content/output/Noto-ur.ttf\", \"Noto Nastaliq Urdu\", \"Noto Naskh Arabic\", \"Arial\"]\n",
        "color = \"white\" #@param [\"white\", \"black\"]\n",
        "subtitle_fontsize = 24 #@param {type:\"integer\"}\n",
        "stroke_color = \"black\" #@param [\"white\", \"black\"]\n",
        "stroke_width = 1.5 #@param {type:\"number\"}\n",
        "subtitle_position = \"center\" #@param [\"center\", \"top\", \"bottom\"]\n",
        "\n",
        "from moviepy.editor import VideoFileClip, CompositeVideoClip, TextClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "\n",
        "# Load the video\n",
        "video = VideoFileClip(\"output/composite_video.mp4\")\n",
        "\n",
        "if use_subtitles == \"YES\":\n",
        "    # Define a lambda function for styling the subtitles\n",
        "    generator = lambda txt: TextClip(txt, font=subtitle_font, fontsize=subtitle_fontsize,\n",
        "                                      color=color, size=(video.w, video.h),\n",
        "                                      stroke_color=stroke_color, stroke_width=stroke_width)\n",
        "\n",
        "    # Create a SubtitlesClip\n",
        "    subtitles = SubtitlesClip(\"output/voice.srt\", generator)\n",
        "\n",
        "    # Adjust subtitle position based on the user's choice\n",
        "    if subtitle_position == \"left-right\":\n",
        "        subtitle_position = ('left', 'bottom')\n",
        "    elif subtitle_position == \"up-down\":\n",
        "        subtitle_position = ('center', 'bottom')\n",
        "    subtitles = subtitles.set_position(subtitle_position)\n",
        "else:\n",
        "    subtitles = None\n",
        "\n",
        "# Composite video clip with subtitles\n",
        "clips = [video]\n",
        "if subtitles:\n",
        "    clips.append(subtitles)\n",
        "result = CompositeVideoClip(clips)\n",
        "\n",
        "# Export the final video with subtitles\n",
        "result.write_videofile(\"output/final_video.mp4\", fps=video.fps, codec=\"libx264\",\n",
        "                       audio_codec=\"aac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqgE0xwE_0S-"
      },
      "outputs": [],
      "source": [
        "play(\"output/final_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzsL8txM4aOg"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h2>Upload The Final Video To Youtube</h2>\n",
        "\n",
        "\n",
        "\n",
        "with open(\"client_secrets.json\", \"w\") as f:\n",
        "  f.write('CLIENT_SECRETS'))\n",
        "with open(\"upload_video.py-oauth2.json\", \"w\") as f:\n",
        "  f.write(userdata.get('PY_OAUTH2'))\n",
        "\n",
        "!wget https://gist.githubusercontent.com/tajpouria/f37f4999ba4913369878b1c12be83436/raw/6ec94f4e1457a688fcda9869156cbad3af89b0c9/upload_video.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByQ1DaK58pl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KV5VAMGTCtZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THkuBlcBC24M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Roman_string"
      ],
      "metadata": {
        "id": "fgWxIlnhDDwr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}